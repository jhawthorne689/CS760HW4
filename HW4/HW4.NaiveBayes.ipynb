{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138354e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: done\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/johnhawthorne/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ffmpeg-4.3                 |       h0a44026_0        10.1 MB  pytorch\n",
      "    gnutls-3.6.5               |    h91ad68e_1002         1.6 MB\n",
      "    lame-3.100                 |       h1de35cc_0         316 KB\n",
      "    nettle-3.4.1               |       h3018a27_0         604 KB\n",
      "    openh264-2.1.1             |       h8346a28_0         655 KB\n",
      "    pytorch-2.0.0              |          py3.9_0        76.4 MB  pytorch\n",
      "    torchvision-0.15.0         |         py39_cpu         6.4 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        96.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ffmpeg             pytorch/osx-64::ffmpeg-4.3-h0a44026_0 None\n",
      "  gnutls             pkgs/main/osx-64::gnutls-3.6.5-h91ad68e_1002 None\n",
      "  lame               pkgs/main/osx-64::lame-3.100-h1de35cc_0 None\n",
      "  nettle             pkgs/main/osx-64::nettle-3.4.1-h3018a27_0 None\n",
      "  openh264           pkgs/main/osx-64::openh264-2.1.1-h8346a28_0 None\n",
      "  pytorch            pytorch/osx-64::pytorch-2.0.0-py3.9_0 None\n",
      "  torchvision        pytorch/osx-64::torchvision-0.15.0-py39_cpu None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ffmpeg-4.3           | 10.1 MB   | ##################################### | 100% \n",
      "lame-3.100           | 316 KB    | ##################################### | 100% \n",
      "openh264-2.1.1       | 655 KB    | ##################################### | 100% \n",
      "nettle-3.4.1         | 604 KB    | ##################################### | 100% \n",
      "torchvision-0.15.0   | 6.4 MB    | ##################################### | 100% \n",
      "gnutls-3.6.5         | 1.6 MB    | ##################################### | 100% \n",
      "pytorch-2.0.0        | 76.4 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1b91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "d2a1d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is for all data files in the directory, no split, just a test of code concept\n",
    "'''\n",
    "\n",
    "# files = Path('hw4.info/languageID').glob('*')\n",
    "files = Path('hw4.info/languageID').glob('*')\n",
    "# glob('dir/*[0-9].*')\n",
    "\n",
    "# characters also have 'documents' and 'total_char' which is total count to get priors.\n",
    "characters = ['total_char','documents','a', 'b', 'c', 'd', 'e', 'f', 'g','h',\n",
    "                    'i','j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v','w', 'x', 'y', 'z', ' ']\n",
    "language_dict = {'e': [0], 'j': [0], 's': [0]}\n",
    "counts = pd.DataFrame(language_dict, index = characters)\n",
    "alpha = 1/2\n",
    "\n",
    "# so now we're looping through the files converting them to list of characters\n",
    "# not these lists include newline characters\n",
    "for file in files:\n",
    "    try:\n",
    "        x = list(open(file).read())\n",
    "    except: continue\n",
    "   \n",
    "    language = str(file)[20] \n",
    "    counts[language]['documents'] += 1\n",
    "    \n",
    "    for i in x:\n",
    "        if i not in characters:\n",
    "            continue\n",
    "        else:\n",
    "            counts[language]['total_char'] += 1\n",
    "            counts[language][i] += 1\n",
    "        \n",
    "# counts\n",
    "CondProbs = counts.iloc[1:,:] + alpha\n",
    "CondProbs['e'][1:] = CondProbs['e'][1:]/(counts['e']['total_char'] + (len(characters) - 2)*alpha)\n",
    "CondProbs['j'][1:] = CondProbs['j'][1:]/(counts['j']['total_char'] + (len(characters) - 2)*alpha)\n",
    "CondProbs['s'][1:] = CondProbs['s'][1:]/(counts['s']['total_char'] + (len(characters) - 2)*alpha)\n",
    "CondProbs.iloc[0,:] = CondProbs.iloc[0,:]/( counts.iloc[1,0] + counts.iloc[1,1] + \n",
    "                                           counts.iloc[1,2] + len(language_dict)*alpha  )\n",
    "\n",
    "CondProbs = CondProbs.rename(index={'documents':'prior'})\n",
    "# CondProbs.loc['prior'] = CondProbs.loc['prior']/(CondProbs['e']['prior'] + CondProbs['j']['prior'] \n",
    "#                                                  + CondProbs['s']['prior'] + (len(characters) - 2)*alpha)\n",
    "# CondProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d7e7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get rid of the space characters now\n",
    "# x = list(open('hw4.info/languageID/e0.txt').read())\n",
    "# type(x)\n",
    "# x\n",
    "# x_fin = []\n",
    "# for i in x:\n",
    "#     if i == '\\n':\n",
    "#         continue\n",
    "#     else: x_fin.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba09c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>j</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.060169</td>\n",
       "      <td>0.131766</td>\n",
       "      <td>0.104560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>0.008233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>0.037526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>0.039746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.105369</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.113811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.008603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.007184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.047216</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.055411</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.049860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.057409</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.052943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.020519</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.057922</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.054177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.064464</td>\n",
       "      <td>0.091163</td>\n",
       "      <td>0.072492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.024267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.007678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.053825</td>\n",
       "      <td>0.042804</td>\n",
       "      <td>0.059295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.066182</td>\n",
       "      <td>0.042175</td>\n",
       "      <td>0.065770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.080126</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>0.035614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.026664</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>0.033702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0.009285</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.005889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.015496</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.013844</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.007863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.179250</td>\n",
       "      <td>0.123449</td>\n",
       "      <td>0.168265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              e         j         s\n",
       "prior  0.333333  0.333333  0.333333\n",
       "a      0.060169  0.131766  0.104560\n",
       "b      0.011135  0.010867  0.008233\n",
       "c      0.021510  0.005486  0.037526\n",
       "d      0.021973  0.017226  0.039746\n",
       "e      0.105369  0.060205  0.113811\n",
       "f      0.018933  0.003879  0.008603\n",
       "g      0.017479  0.014012  0.007184\n",
       "h      0.047216  0.031762  0.004533\n",
       "i      0.055411  0.097033  0.049860\n",
       "j      0.001421  0.002341  0.006629\n",
       "k      0.003734  0.057409  0.000278\n",
       "l      0.028977  0.001433  0.052943\n",
       "m      0.020519  0.039799  0.025809\n",
       "n      0.057922  0.056711  0.054177\n",
       "o      0.064464  0.091163  0.072492\n",
       "p      0.016752  0.000874  0.024267\n",
       "q      0.000562  0.000105  0.007678\n",
       "r      0.053825  0.042804  0.059295\n",
       "s      0.066182  0.042175  0.065770\n",
       "t      0.080126  0.056990  0.035614\n",
       "u      0.026664  0.070617  0.033702\n",
       "v      0.009285  0.000245  0.005889\n",
       "w      0.015496  0.019742  0.000093\n",
       "x      0.001156  0.000035  0.002498\n",
       "y      0.013844  0.014151  0.007863\n",
       "z      0.000628  0.007722  0.002683\n",
       "       0.179250  0.123449  0.168265"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This is for [e,j,s][0-9].txt only\n",
    "'''\n",
    "files = Path('hw4.info/languageID').glob('?[0-9].txt')\n",
    "\n",
    "\n",
    "characters = ['total_char','documents','a', 'b', 'c', 'd', 'e', 'f', 'g','h',\n",
    "                    'i','j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v','w', 'x', 'y', 'z', ' ']\n",
    "language_dict = {'e': [0], 'j': [0], 's': [0]}\n",
    "counts = pd.DataFrame(language_dict, index = characters)\n",
    "alpha = 1/2\n",
    "# count = 0\n",
    "# so now we're looping through the files converting them to list of characters\n",
    "# not these lists include newline characters\n",
    "for file in files:\n",
    "#     count+=1\n",
    "    \n",
    "    try:\n",
    "        x = list(open(file).read())\n",
    "    except: continue\n",
    "#     print(file)\n",
    "    language = str(file)[20]\n",
    "#     print(language)\n",
    "    counts[language]['documents'] += 1\n",
    "    for i in x:\n",
    "        if i not in characters:\n",
    "            continue\n",
    "        else: \n",
    "            #increase total count for language type (includes space characters)\n",
    "            counts[language]['total_char'] += 1\n",
    "            counts[language][i] += 1\n",
    "        \n",
    "\n",
    "\n",
    "CondProbs = counts.iloc[1:,:] + alpha\n",
    "CondProbs['e'][1:] = CondProbs['e'][1:]/(counts['e']['total_char'] + (len(characters) - 2)*alpha)\n",
    "CondProbs['j'][1:] = CondProbs['j'][1:]/(counts['j']['total_char'] + (len(characters) - 2)*alpha)\n",
    "CondProbs['s'][1:] = CondProbs['s'][1:]/(counts['s']['total_char'] + (len(characters) - 2)*alpha)\n",
    "CondProbs.iloc[0,:] = CondProbs.iloc[0,:]/( counts.iloc[1,0] + counts.iloc[1,1] + \n",
    "                                           counts.iloc[1,2] + len(language_dict)*alpha  )\n",
    "CondProbs = CondProbs.rename(index={'documents':'prior'})\n",
    "TrainingData0to9 = CondProbs\n",
    "TrainingData0to9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e012f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4565c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCounts(document):\n",
    "    '''\n",
    "    Send in Document name, breaks into string, get count of each character to return\n",
    "    '''\n",
    "    characters = ['total_char','a', 'b', 'c', 'd', 'e', 'f', 'g','h','i','j',\n",
    "                  'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v','w', 'x', 'y', 'z', ' ']\n",
    "    get_counts = pd.DataFrame({'count':[0]*len(characters)}, index = characters)\n",
    "    x = list(open(document).read())\n",
    "    for i in x:\n",
    "        if i not in characters:\n",
    "            continue\n",
    "        else:\n",
    "            get_counts['count']['total_char'] += 1\n",
    "            get_counts['count'][i] += 1\n",
    "    return get_counts   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0822aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePrediction(TrainData, TestData, alpha):\n",
    "    '''\n",
    "    df TrainData is all conditional prob, df Test Data is counts of all char in TestData\n",
    "    '''     \n",
    "    LogProbXgivenY = {}\n",
    "    for column in TrainData:\n",
    "        log_prob = 0\n",
    "        # recall TestData has 0-th index as total_char and TrainData has the priors\n",
    "        for i in range(len(TrainData)-1):\n",
    "            log_prob = log_prob + TestData['count'][i+1] * np.log(TrainData[column][i+1])\n",
    "\n",
    "        LogProbXgivenY[column] = log_prob\n",
    "\n",
    "    TestProb = (TestData + alpha)/(TestData['count']['total_char'] + (len(TestData)-1)*alpha)\n",
    "    LogProbX = float(np.sum(np.log(TestProb.loc['a':])))\n",
    "\n",
    "    LogProbYgivenX = {}\n",
    "\n",
    "    for i in LogProbXgivenY:\n",
    "        LogProbYgivenX[i] = LogProbXgivenY[i] - LogProbX + np.log(TrainData[i][0])\n",
    "    \n",
    "#     print(LogProbXgivenY)\n",
    "#     print(LogProbYgivenX)\n",
    "    return max(LogProbYgivenX, key = LogProbYgivenX.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2529d4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "alpha = 1/2\n",
    "TestDocData = GetCounts('hw4.info/languageID/e10.txt')\n",
    "Prediction = MakePrediction(TrainingData0to9, TestDocData, alpha)\n",
    "print(Prediction)\n",
    "# TestDocData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "aad72039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateConfusionMatrix(Directory, FilePaths):\n",
    "    \n",
    "    \n",
    "    ConfusionMatrix = pd.DataFrame({'e':0,'s':0, 'j':0}, index = \n",
    "                                   ['e','s','j'])\n",
    "    \n",
    "    TestFiles = Path(Directory).glob(FilePaths)\n",
    "    \n",
    "    for file in TestFiles:\n",
    "#         print(file)\n",
    "        TestDocCounts = GetCounts(file)\n",
    "        Prediction = MakePrediction(TrainingData0to9, TestDocCounts, alpha)\n",
    "        Actual_Val = str(file)[20]\n",
    "        ConfusionMatrix[Actual_Val][Prediction] += 1\n",
    "\n",
    "    return ConfusionMatrix\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "addbedf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    e   s   j\n",
       "e  10   0   0\n",
       "s   0  10   0\n",
       "j   0   0  10"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenerateConfusionMatrix('hw4.info/languageID', '?1[0-9].txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "a70401f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We are to take a random test document, shuffle it beyond recognition, then see how it affects our classifier\n",
    "It should not affect it because our counts will for each character will still be the same.\n",
    "'''\n",
    "RandomTestDoc = GetCounts('hw4.info/languageID/j16.txt')\n",
    "\n",
    "characters = ['total_char','a', 'b', 'c', 'd', 'e', 'f', 'g','h','i','j',\n",
    "                  'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v','w', 'x', 'y', 'z', ' ']\n",
    "get_counts = pd.DataFrame({'count':[0]*len(characters)}, index = characters)\n",
    "x = list(open('hw4.info/languageID/j16.txt').read())\n",
    "random.shuffle(x)\n",
    "for i in x:\n",
    "    if i not in characters:\n",
    "        continue\n",
    "    else:\n",
    "        get_counts['count']['total_char'] += 1\n",
    "        get_counts['count'][i] += 1\n",
    "# get_counts\n",
    "# RandomTestDoc\n",
    "'''\n",
    "For RandomTestDoc, we get the counts of the char for the unshuffled document\n",
    "For get_counts, we shuffle, then get the counts. Both the counts are the same.\n",
    "Thus the niave bayes classifier behaves the same for both inputs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeed546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
